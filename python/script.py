def main():
    import argparse
    import os
    import time
    import json
    import re
    from pathlib import Path
    from datetime import datetime
    
    print("üöÄ G√©n√©rateur de Vid√©os √âducatives - Deep Learning Enhanced")
    print("=" * 60)
    
    parser = argparse.ArgumentParser(description="G√©n√©ration diapositives HTML et vid√©o avec avatar + IA")
    parser.add_argument("markdown_file", nargs='?', help="Fichier markdown √† traiter (optionnel - mode interactif si absent)")
    parser.add_argument("--model", default="microsoft/phi-2", help="Mod√®le de langage √† utiliser")
    parser.add_argument("--html", action="store_true", help="G√©n√©rer des diapositives HTML")
    parser.add_argument("--no-avatar", action="store_true", help="D√©sactiver l'ajout de l'avatar")
    parser.add_argument("--avatar-path", help="Chemin personnalis√© vers la vid√©o de l'avatar", 
                        default="H:/formation-main/avatar.mp4")
    parser.add_argument("--output", "-o", help="Nom ou dossier de sortie pour les pr√©sentations")
    
    # NOUVEAU: Support lecture directe
    parser.add_argument("--no-page-numbers", action="store_true",
                       help="Ne pas mentionner les num√©ros de page dans la narration (lecture fluide)")
    
    args = parser.parse_args()
    
    # Mode interactif si aucun fichier fourni
    if not args.markdown_file:
        print("üéÆ Mode interactif activ√© - Aucun fichier sp√©cifi√©")
        print("-" * 60)
        
        # Chercher des fichiers markdown dans le r√©pertoire courant
        import glob
        md_files = glob.glob("*.md")
        
        if md_files:
            print("üìÅ Fichiers Markdown trouv√©s dans le r√©pertoire :")
            for i, file in enumerate(md_files, 1):
                print(f"   {i}. {file}")
            
            try:
                choice = input("\nChoisissez un fichier (num√©ro) ou tapez un chemin : ").strip()
                if choice.isdigit() and 1 <= int(choice) <= len(md_files):
                    args.markdown_file = md_files[int(choice) - 1]
                elif choice:
                    args.markdown_file = choice
                else:
                    # Cr√©er un fichier de d√©monstration
                    args.markdown_file = create_demo_file()
            except (KeyboardInterrupt, EOFError):
                print("\n‚ùå Annul√© par l'utilisateur")
                exit(0)
        else:
            print("üìù Aucun fichier .md trouv√©. Cr√©ation d'un fichier de d√©monstration...")
            args.markdown_file = create_demo_file()
        
        print(f"‚úÖ Fichier s√©lectionn√©: {args.markdown_file}")
        print("-" * 60)
    
    # Marquer le d√©but du traitement pour les statistiques
    start_time = time.time()
    
    # Afficher les param√®tres s√©lectionn√©s
    print(f"üìÑ Fichier d'entr√©e: {args.markdown_file}")
    print(f"ü§ñ Mod√®le IA: {args.model}")
    print(f"üìñ Mode lecture: {'Directe (fluide)' if args.no_page_numbers else 'Standard (avec pages)'}")
    print(f"üé¨ Format: {'HTML + Vid√©o' if args.html else 'Vid√©o uniquement'}")
    print(f"üë§ Avatar: {'D√©sactiv√©' if args.no_avatar else 'Activ√©'}")
    print("-" * 60)

    # V√©rifier l'existence du fichier d'entr√©e
    if not os.path.exists(args.markdown_file):
        print(f"‚ùå Fichier non trouv√©: {args.markdown_file}")
        exit(1)

    # Analyser le document avec IA
    print("üß† Analyse IA du document en cours...")
    content_analysis = analyze_document_content(args.markdown_file)
    print(f"üìä Type de contenu: {content_analysis['content_type']}")
    print(f"üìà Complexit√©: {content_analysis['complexity']}")
    print(f"üìù Longueur estim√©e: {content_analysis['estimated_length']} mots")
    
    # V√©rifier et configurer l'avatar
    avatar_path = None
    if not args.no_avatar:
        avatar_path = configure_avatar(args.avatar_path)
    else:
        print("üë§ L'avatar a √©t√© d√©sactiv√© avec --no-avatar")

    # Charger l'historique d'apprentissage
    learning_data = load_learning_history()
    total_files = len(learning_data.get('processed_files', []))
    improvement_level = learning_data.get('improvement_level', 1)
    total_videos = learning_data.get('total_videos_generated', 0)
    
    print(f"üìö Historique d'apprentissage: {total_files} fichiers trait√©s")
    print(f"üé¨ Total vid√©os g√©n√©r√©es: {total_videos}")
    print(f"üß† Niveau IA actuel: {improvement_level}/5")
    
    if improvement_level >= 3:
        print("üî• Fonctionnalit√©s avanc√©es d√©bloqu√©es!")
    if improvement_level >= 4:
        print("‚ö° Auto-am√©lioration activ√©e!")
    if improvement_level >= 5:
        print("üåü IA Expert - Niveau maximum!")
    
    print("-" * 60)

    # Initialiser les mod√®les
    print(f"ü§ñ Initialisation du mod√®le {args.model}...")
    initialize_models(args.model)

    # Traiter le contenu selon les options
    print("üîÑ Traitement du contenu avec optimisations IA...")
    processed_content = process_markdown_content(args.markdown_file, args, content_analysis)

    # Appeler videoseul.py avec les bons param√®tres
    print("üé¨ Lancement de la g√©n√©ration vid√©o...")
    video_result = call_videoseul(args, processed_content, content_analysis, avatar_path)
    
    # Calculer le temps de traitement
    processing_time = time.time() - start_time
    
    # Enregistrer dans l'historique d'apprentissage
    save_processing_record(args, content_analysis, video_result, processing_time, learning_data)
    
    # Afficher les r√©sultats et suggestions
    print("\n" + "=" * 60)
    print("‚úÖ G√âN√âRATION TERMIN√âE AVEC SUCC√àS!")
    if video_result:
        print(f"üìÅ Fichier de sortie: {video_result}")
    print(f"‚è±Ô∏è Temps de traitement: {processing_time:.1f} secondes")
    
    # Afficher les suggestions d'optimisation
    show_optimization_suggestions(learning_data, args.model)
    print("=" * 60)


def create_demo_file():
    """Cr√©e un fichier Markdown de d√©monstration"""
    demo_content = """# üéì D√©monstration VideoSeul

## Introduction

Bienvenue dans cette d√©monstration du g√©n√©rateur de vid√©os √©ducatives avec IA !

## Fonctionnalit√©s

### ‚ú® Analyse Automatique
- D√©tection du type de contenu (technique, √©ducatif, business, cr√©atif)
- Optimisation selon la complexit√©
- Suggestions intelligentes

### üé¨ G√©n√©ration Vid√©o
- Cr√©ation automatique de diapositives
- Narration synchronis√©e
- Support des avatars
- Transitions fluides

### üß† Intelligence Artificielle
- Am√©lioration du contenu
- Apprentissage des pr√©f√©rences
- Recommandations personnalis√©es

## Types de Contenu Support√©s

### üìö √âducatif
Optimis√© pour l'apprentissage avec transitions p√©dagogiques.

### üî¨ Technique  
Pauses automatiques sur les termes complexes.

### üíº Business
Mise en valeur des KPI et m√©triques importantes.

### üé® Cr√©atif
Fluidit√© narrative am√©lior√©e.

## Conclusion

Cette d√©monstration montre les capacit√©s du syst√®me. Utilisez vos propres fichiers pour de meilleurs r√©sultats !

---
*G√©n√©r√© automatiquement par VideoSeul*
"""
    
    demo_file = "demo_videoseul.md"
    with open(demo_file, 'w', encoding='utf-8') as f:
        f.write(demo_content)
    
    print(f"üìÑ Fichier de d√©monstration cr√©√©: {demo_file}")
    return demo_file


def analyze_document_content(file_path):
    """
    Analyse le contenu du document pour d√©terminer son type et sa complexit√©
    """
    import re
    from pathlib import Path
    
    try:
        file_path = Path(file_path)
        content_info = {
            "complexity": "simple",
            "content_type": "general",
            "estimated_length": 0,
            "keywords": []
        }
        
        # Lire le contenu
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        text_lower = content.lower()
        word_count = len(content.split())
        content_info["estimated_length"] = word_count
        
        # Analyser le nom du fichier pour des indices
        file_name = file_path.name.lower()
        if any(word in file_name for word in ['technical', 'tech', 'api', 'documentation', 'manual', 'guide']):
            content_info["content_type"] = "technical"
        elif any(word in file_name for word in ['course', 'lesson', 'tutorial', 'education', 'formation', 'academy']):
            content_info["content_type"] = "educational"  
        elif any(word in file_name for word in ['business', 'report', 'analysis', 'presentation', 'meeting']):
            content_info["content_type"] = "business"
        elif any(word in file_name for word in ['creative', 'story', 'design', 'marketing', 'brand']):
            content_info["content_type"] = "creative"
        
        # Analyser le contenu pour affiner le type
        technical_keywords = ['algorithm', 'function', 'class', 'method', 'api', 'database', 'server', 'code', 'python', 'javascript', 'sql', 'framework', 'aws', 'cloud']
        educational_keywords = ['learn', 'study', 'course', 'lesson', 'chapter', 'exercise', 'example', 'tutorial', 'education', 'formation']
        business_keywords = ['revenue', 'profit', 'market', 'sales', 'business', 'customer', 'strategy', 'analysis', 'report']
        creative_keywords = ['story', 'design', 'creative', 'art', 'brand', 'marketing', 'campaign', 'narrative']
        
        # Compter les mots-cl√©s par cat√©gorie
        tech_score = sum(1 for kw in technical_keywords if kw in text_lower)
        edu_score = sum(1 for kw in educational_keywords if kw in text_lower)
        business_score = sum(1 for kw in business_keywords if kw in text_lower)
        creative_score = sum(1 for kw in creative_keywords if kw in text_lower)
        
        # D√©terminer le type de contenu bas√© sur le score le plus √©lev√©
        scores = {
            "technical": tech_score,
            "educational": edu_score, 
            "business": business_score,
            "creative": creative_score
        }
        
        if max(scores.values()) > 0:
            content_info["content_type"] = max(scores, key=scores.get)
        
        # D√©terminer la complexit√©
        if word_count > 2000 or tech_score > 5:
            content_info["complexity"] = "complex"
        elif word_count > 500 or max(scores.values()) > 2:
            content_info["complexity"] = "medium"
        
        return content_info
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de l'analyse du contenu: {e}")
        return {
            "complexity": "simple",
            "content_type": "general", 
            "estimated_length": 0,
            "keywords": []
        }


def configure_avatar(avatar_path):
    """
    Configure et v√©rifie le chemin de l'avatar
    """
    import os
    
    if os.path.exists(avatar_path):
        print(f"üë§ Avatar trouv√©: {avatar_path}")
        return avatar_path
    else:
        print(f"‚ö†Ô∏è Avatar non trouv√© √†: {avatar_path}")
        # Essayer d'autres chemins potentiels
        alternative_paths = [
            "H:/formation-main/avatar.mp4",
            "./avatar.mp4",
            "../avatar.mp4",
            os.path.join(os.path.dirname(__file__), "avatar.mp4")
        ]
        for alt_path in alternative_paths:
            if os.path.exists(alt_path):
                print(f"üë§ Avatar alternatif trouv√©: {alt_path}")
                return alt_path
        
        print("‚ö†Ô∏è Aucun avatar trouv√©. La vid√©o sera cr√©√©e sans avatar.")
        return None


def load_learning_history():
    """
    Charge l'historique d'apprentissage pour les recommandations
    CORRECTION: Utiliser le m√™me fichier que l'interface Python
    """
    import json
    from pathlib import Path
    
    # UTILISER LE M√äME FICHIER QUE L'INTERFACE PYTHON
    history_file = Path("video_generator_data.json")  # ‚Üê CORRECTION ICI
    if history_file.exists():
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # Adapter le format pour la compatibilit√©
                return {
                    "processed_files": data.get('processed_files', []),
                    "model_performance": data.get('model_performance', {}),
                    "content_statistics": data.get('learning_patterns', {}),
                    "improvement_level": data.get('improvement_level', 1),
                    "total_videos_generated": data.get('total_videos_generated', 0)
                }
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du chargement de l'historique: {e}")
    
    return {
        "processed_files": [],
        "model_performance": {},
        "content_statistics": {},
        "improvement_level": 1,
        "total_videos_generated": 0
    }


def process_markdown_content(file_path, args, content_analysis):
    """
    Traite le contenu Markdown selon les options et optimisations IA
    """
    import re
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        with open(file_path, 'r', encoding='latin-1') as f:
            content = f.read()
        print("üîÑ Fichier d√©tect√© en encodage latin-1, conversion effectu√©e")
    
    # Appliquer le mode lecture directe si demand√©
    if args.no_page_numbers:
        print("üìñ Application du mode lecture directe...")
        content = remove_page_numbers(content)
    else:
        print("üìÑ Conservation du mode standard avec pagination")
        content = ensure_page_structure(content)
    
    # Optimiser selon le type de contenu
    content = optimize_content_for_type(content, content_analysis)
    
    return content


def remove_page_numbers(content):
    """
    Retire les r√©f√©rences aux num√©ros de page pour une lecture fluide
    """
    import re
    
    # Retirer les patterns de pagination (CORRECTION COMPL√àTE)
    patterns_to_remove = [
        r'^Page \d+[:.]\s*',           # "Page 1:", "Page 2."
        r'^---\s*Page \d+\s*---\s*$',  # "--- Page X ---"  ‚Üê LIGNE CORRIG√âE
        r'\n\s*Page \d+\s*\n',         # Page isol√©e sur une ligne
        r'\[Page \d+\]',               # [Page X]
        r'\(Page \d+\)',               # (Page X)
        r'^\d+\s*$',                   # Num√©ros seuls sur une ligne
    ]
    
    for pattern in patterns_to_remove:
        content = re.sub(pattern, '', content, flags=re.MULTILINE)
    
    # Nettoyer les espaces suppl√©mentaires
    content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
    content = re.sub(r'^\s+', '', content, flags=re.MULTILINE)
    
    print("‚úÖ R√©f√©rences de page supprim√©es - Mode lecture fluide activ√©")
    return content.strip()


def ensure_page_structure(content):
    """
    S'assure que la structure de pagination est coh√©rente
    """
    import re
    
    # Si pas de num√©ros de page d√©tect√©s, les ajouter logiquement
    if not re.search(r'Page \d+', content):
        # Diviser le contenu en sections logiques
        sections = content.split('\n\n')
        numbered_sections = []
        page_num = 1
        current_page_content = []
        word_count_per_page = 0
        
        for section in sections:
            if section.strip():
                words_in_section = len(section.split())
                
                # Nouvelle page si la section est longue ou on a d√©j√† beaucoup de contenu
                if word_count_per_page > 200 or words_in_section > 300:
                    if current_page_content:
                        numbered_sections.append(f"Page {page_num}\n\n" + '\n\n'.join(current_page_content))
                        page_num += 1
                        current_page_content = []
                        word_count_per_page = 0
                
                current_page_content.append(section)
                word_count_per_page += words_in_section
        
        # Ajouter la derni√®re page
        if current_page_content:
            numbered_sections.append(f"Page {page_num}\n\n" + '\n\n'.join(current_page_content))
        
        content = '\n\n'.join(numbered_sections)
        print(f"‚úÖ Structure de pagination cr√©√©e - {page_num} pages")
    
    return content


def optimize_content_for_type(content, content_analysis):
    """
    Optimise le contenu selon son type d√©tect√©
    """
    import re
    
    content_type = content_analysis.get("content_type", "general")
    complexity = content_analysis.get("complexity", "simple")
    
    print(f"üéØ Optimisation pour contenu {content_type} de complexit√© {complexity}")
    
    if content_type == "technical":
        content = optimize_technical_content(content)
    elif content_type == "educational":
        content = optimize_educational_content(content)
    elif content_type == "business":
        content = optimize_business_content(content)
    elif content_type == "creative":
        content = optimize_creative_content(content)
    
    return content


def optimize_technical_content(content):
    """Optimise le contenu technique avec des pauses pour clarification"""
    import re
    
    # Ajouter des pauses apr√®s les termes techniques complexes
    technical_terms = [
        r'\b(API|REST|JSON|XML|HTTP|HTTPS|SQL|NoSQL|AWS|Azure|Docker|Kubernetes)\b',
        r'\b(algorithm|function|class|method|database|framework|library)\b',
        r'\b(authentication|authorization|encryption|deployment|scalability)\b'
    ]
    
    for pattern in technical_terms:
        content = re.sub(pattern, r'\1... ', content, flags=re.IGNORECASE)
    
    # Ajouter des transitions explicatives
    content = re.sub(r'\n(#{1,3} .+)\n', r'\n\nNous allons maintenant expliquer \1\n', content)
    content = re.sub(r'\nNous allons maintenant expliquer # ', r'\nNous allons maintenant expliquer ', content)
    
    print("üî¨ Optimisation technique appliqu√©e - Pauses et clarifications ajout√©es")
    return content


def optimize_educational_content(content):
    """Optimise le contenu √©ducatif avec une structure p√©dagogique"""
    import re
    
    # Ajouter des transitions p√©dagogiques
    content = re.sub(r'\n(#{1,3} .+)\n', r'\n\nMaintenant, nous allons √©tudier \1\n', content)
    content = re.sub(r'\nMaintenant, nous allons √©tudier # ', r'\nMaintenant, nous allons √©tudier ', content)
    
    # Ajouter des r√©sum√©s entre les sections
    sections = content.split('\n\n')
    enhanced_sections = []
    
    for i, section in enumerate(sections):
        enhanced_sections.append(section)
        # Ajouter un r√©sum√© tous les 3 sections
        if i > 0 and i % 3 == 0 and '# ' in section:
            enhanced_sections.append("R√©capitulons ce que nous venons d'apprendre...")
    
    content = '\n\n'.join(enhanced_sections)
    print("üìö Optimisation √©ducative appliqu√©e - Structure p√©dagogique renforc√©e")
    return content


def optimize_business_content(content):
    """Optimise le contenu business avec emphase sur les points cl√©s"""
    import re
    
    # Emphasize key business terms
    business_terms = r'\b(ROI|profit|revenue|market|strategy|customer|growth|analysis|KPI|budget)\b'
    content = re.sub(business_terms, r'**\1**', content, flags=re.IGNORECASE)
    
    # Ajouter des transitions orient√©es r√©sultats
    content = re.sub(r'\n(#{1,3} .+)\n', r'\n\nExaminons maintenant \1\n', content)
    
    print("üíº Optimisation business appliqu√©e - Points cl√©s mis en valeur")
    return content


def optimize_creative_content(content):
    """Optimise le contenu cr√©atif avec fluidit√© narrative"""
    # Ajouter des transitions narratives
    transitions = [
        "Ensuite, ",
        "De plus, ",
        "Par ailleurs, ",
        "En outre, ",
        "Maintenant, "
    ]
    
    paragraphs = content.split('\n\n')
    enhanced_paragraphs = []
    
    for i, paragraph in enumerate(paragraphs):
        if i > 0 and not paragraph.startswith('#') and len(paragraph) > 50:
            transition = transitions[i % len(transitions)]
            if not paragraph.startswith(tuple(transitions)):
                paragraph = transition + paragraph
        enhanced_paragraphs.append(paragraph)
    
    content = '\n\n'.join(enhanced_paragraphs)
    print("üé® Optimisation cr√©ative appliqu√©e - Fluidit√© narrative am√©lior√©e")
    return content


def call_videoseul(args, processed_content, content_analysis, avatar_path):
    """
    Appelle videoseul.py avec les param√®tres appropri√©s
    """
    import subprocess
    import tempfile
    import os
    from pathlib import Path
    
    # Cr√©er un fichier temporaire avec le contenu trait√©
    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as temp_file:
        temp_file.write(processed_content)
        temp_markdown_path = temp_file.name
    
    try:
        # Construire la commande pour videoseul.py
        cmd = [
            'python', 'videoseul.py',
            temp_markdown_path,
            '--model', args.model
        ]
        
        if args.no_page_numbers:
            cmd.append('--direct-reading')  # Utiliser --direct-reading pour compatibilit√© interface
        
        if args.no_avatar:
            cmd.append('--no-avatar')
        elif avatar_path:
            cmd.extend(['--avatar-path', avatar_path])
        
        if args.output:
            cmd.extend(['--output', args.output])
        
        # Ex√©cuter videoseul.py
        print(f"üé¨ Ex√©cution: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.path.dirname(__file__))
        
        if result.returncode == 0:
            print("‚úÖ videoseul.py ex√©cut√© avec succ√®s!")
            
            # Chercher le fichier de sortie g√©n√©r√©
            output_dir = Path(temp_markdown_path).parent / "output"
            if output_dir.exists():
                video_files = list(output_dir.glob("*.mp4"))
                if video_files:
                    return str(video_files[0])
            
            # Si pas trouv√©, retourner un chemin par d√©faut
            if args.output:
                return args.output if args.output.endswith('.mp4') else f"{args.output}/video.mp4"
            else:
                return "output/presentation_fidele.mp4"
        else:
            print(f"‚ùå Erreur lors de l'ex√©cution de videoseul.py:")
            print(result.stderr)
            return None
            
    except Exception as e:
        print(f"‚ùå Erreur lors de l'appel √† videoseul.py: {e}")
        return None
    finally:
        # Nettoyer le fichier temporaire
        try:
            os.unlink(temp_markdown_path)
        except:
            pass


def save_processing_record(args, content_analysis, output_path, processing_time, learning_data):
    """
    Sauvegarde l'enregistrement de traitement pour l'apprentissage
    CORRECTION: Utiliser le m√™me format que l'interface Python
    """
    import time
    import os
    import json
    
    # Format compatible avec l'interface Python
    processing_record = {
        'file_path': args.markdown_file,           # ‚Üê M√™me format interface
        'file_name': os.path.basename(args.markdown_file),
        'models_used': [args.model],               # ‚Üê Liste comme interface
        'video_paths': [output_path] if output_path else [],
        'processing_time': processing_time,
        'timestamp': time.strftime("%Y-%m-%dT%H:%M:%S"),  # ‚Üê Format ISO comme interface
        'file_size': os.path.getsize(args.markdown_file),
        'file_type': os.path.splitext(args.markdown_file)[1],
        # Donn√©es suppl√©mentaires pour compatibilit√©
        'content_analysis': content_analysis,
        'options_used': {
            'no_page_numbers': getattr(args, 'no_page_numbers', False),
            'html_mode': args.html,
            'no_avatar': args.no_avatar,
            'custom_output': args.output is not None
        },
        'success': output_path is not None
    }
    
    # Ajouter √† l'historique
    if 'processed_files' not in learning_data:
        learning_data['processed_files'] = []
    learning_data['processed_files'].append(processing_record)
    
    # Mettre √† jour le compteur total de vid√©os (format interface)
    if 'total_videos_generated' not in learning_data:
        learning_data['total_videos_generated'] = 0
    if output_path:
        learning_data['total_videos_generated'] += 1
    
    # Mettre √† jour le niveau d'am√©lioration (format interface)
    total_files = len(learning_data['processed_files'])
    if total_files >= 50:
        learning_data["improvement_level"] = 5
    elif total_files >= 25:
        learning_data["improvement_level"] = 4
    elif total_files >= 10:
        learning_data["improvement_level"] = 3
    elif total_files >= 5:
        learning_data["improvement_level"] = 2
    else:
        learning_data["improvement_level"] = 1
    
    # Mettre √† jour les statistiques de performance des mod√®les
    if 'model_performance' not in learning_data:
        learning_data['model_performance'] = {}
    
    model = args.model
    if model not in learning_data['model_performance']:
        learning_data['model_performance'][model] = {
            'count': 0,
            'total_time': 0,
            'avg_time': 0
        }
    
    perf = learning_data['model_performance'][model]
    perf['count'] += 1
    perf['total_time'] += processing_time
    perf['avg_time'] = perf['total_time'] / perf['count']
    
    # Sauvegarder dans le M√äME fichier que l'interface
    try:
        with open("video_generator_data.json", 'w', encoding='utf-8') as f:  # ‚Üê M√äME FICHIER
            json.dump(learning_data, f, ensure_ascii=False, indent=2)
        print("üíæ Historique d'apprentissage mis √† jour et synchronis√© avec l'interface")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la sauvegarde: {e}")


def show_optimization_suggestions(learning_data, current_model):
    """
    Affiche des suggestions d'optimisation bas√©es sur l'apprentissage
    CORRECTION: Compatible avec le format de l'interface Python
    """
    import os
    
    print("\nüß† SUGGESTIONS D'OPTIMISATION IA:")
    print("-" * 40)
    
    processed_files = learning_data.get('processed_files', [])
    model_perf = learning_data.get('model_performance', {})
    improvement_level = learning_data.get('improvement_level', 1)
    total_videos = learning_data.get('total_videos_generated', 0)
    
    # Afficher les statistiques g√©n√©rales
    print(f"üìä Fichiers trait√©s: {len(processed_files)}")
    print(f"üé¨ Vid√©os g√©n√©r√©es: {total_videos}")
    print(f"üß† Niveau IA: {improvement_level}/5")
    
    if len(processed_files) < 2:
        print("üìä Continuez √† utiliser l'outil pour d√©bloquer des suggestions personnalis√©es!")
        
        # Suggestions bas√©es sur le niveau
        if improvement_level >= 3:
            print("üî• Niveau 3 atteint - Fonctionnalit√©s avanc√©es disponibles!")
        if improvement_level >= 4:
            print("‚ö° Niveau 4 atteint - Auto-am√©lioration active!")
        if improvement_level >= 5:
            print("üåü Niveau maximum atteint - IA Expert!")
            
        return
    
    # Analyser les performances des mod√®les
    if model_perf:
        print("üöÄ PERFORMANCES DES MOD√àLES:")
        
        # Trouver le mod√®le le plus rapide
        fastest_model = None
        fastest_time = float('inf')
        
        for model, stats in model_perf.items():
            avg_time = stats.get('avg_time', 0)
            count = stats.get('count', 0)
            
            print(f"   ü§ñ {model.split('/')[-1]}: {avg_time:.1f}s moyenne ({count} utilisations)")
            
            if avg_time > 0 and avg_time < fastest_time and count > 1:
                fastest_time = avg_time
                fastest_model = model
        
        if fastest_model and current_model != fastest_model:
            current_avg = model_perf.get(current_model, {}).get('avg_time', 0)
            if current_avg > fastest_time:
                time_saved = current_avg - fastest_time
                print(f"üí° SUGGESTION: Utilisez {fastest_model.split('/')[-1]} pour √©conomiser {time_saved:.1f}s")
    
    # Analyser les types de contenu les plus fr√©quents
    content_types = {}
    for record in processed_files:
        # Support de l'ancien et nouveau format
        file_type = record.get('file_type', '')
        if not file_type:
            file_path = record.get('file_path', record.get('input_file', ''))
            file_type = os.path.splitext(file_path)[1] if file_path else '.unknown'
        
        content_types[file_type] = content_types.get(file_type, 0) + 1
    
    if content_types:
        most_common = max(content_types, key=content_types.get)
        print(f"üìà Type de fichier le plus trait√©: {most_common} ({content_types[most_common]} fois)")
        
        # Suggestions sp√©cialis√©es
        recommendations = {
            ".md": "Parfait pour microsoft/phi-2 - rapide et efficace",
            ".pdf": "Utilisez google/flan-t5-xxl pour PDF complexes ou google/gemma-7b pour contenu technique",
            ".docx": "mistralai/Mistral-7B-v0.1 excellent pour documents Word",
            ".txt": "microsoft/phi-2 optimal pour fichiers texte simples"
        }
        
        if most_common in recommendations:
            print(f"üéØ RECOMMANDATION: {recommendations[most_common]}")
    
    # Suggestions d'utilisation bas√©es sur l'historique  
    no_page_usage = sum(1 for r in processed_files 
                       if r.get('options_used', {}).get('no_page_numbers', False))
    if no_page_usage > len(processed_files) * 0.5:
        print("üìñ Excellente utilisation du mode lecture directe!")
    
    print("üöÄ L'IA continue d'apprendre pour de meilleures recommandations!")


def initialize_models(model_name):
    """Initialise les mod√®les (impl√©mentation basique)"""
    print(f"ü§ñ Initialisation du mod√®le {model_name}...")
    # Impl√©mentation basique - peut √™tre √©tendue
    pass


if __name__ == "__main__":
    main()
